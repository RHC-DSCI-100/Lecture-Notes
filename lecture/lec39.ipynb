{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plots\n",
    "plots.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "\n",
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c395fb42",
   "metadata": {},
   "source": [
    "# Case Study Education\n",
    "\n",
    "## Estimating Exam Scores\n",
    "\n",
    "Scenario: </br>\n",
    "In a large course with 2 midterm exams, most students took both midterms.</br>\n",
    "John was sick for the second midterm. He emailed the instructor who excused him.\n",
    "\n",
    "Now itâ€™s time to assign John a grade in the course...</br>\n",
    "The course is graded on an absolute scale that allocates 90 points to midterms:\n",
    "* 40 for midterm 1\n",
    "* 50 for midterm 2\n",
    "\n",
    "There are several options: \n",
    "* Give an Incomplete Grade: Next semester, John has to take exam 2.\n",
    "    * What is good and what is bad about this approach?\n",
    "* Scale Up Midterm 1 Score\n",
    "    * E.g., if John scored 21 out of 40 on midterm 1, assign him a score of $21/40*50 = 26.25$ out of 50 on midterm. Equivalently, assign him a total score of $21/40*90 = 47.25$.\n",
    "* Use the Midterm 1 Z-Score\n",
    "    * E.g., if John scored 1 standard deviation below the mean on midterm 1, assign him a midterm 2 score that is 1 standard deviation below the mean.\n",
    "* Use Midterm 1 Percentile\n",
    "    * E.g., if John scored in the 30th percentile on the final, assign him a midterm score that is in the 30th percentile.\n",
    "* Use Linear Regression\n",
    "    * E.g., if John scored 1 standard deviation below the mean on the final, and the correlation coefficient r between midterm and final scores was 0.8 for students who took both, then assign him a midterm score that is 0.8 standard deviations below the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in the Scores for both Midterms\n",
    " \n",
    "scores = Table.read_table(\"scores.csv\")\n",
    "scores.drop(2).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the mean and standard deviation for each midterm. \n",
    "\n",
    "mt1 = scores.column('Midterm 1')\n",
    "mt2 = scores.column('Midterm 2')\n",
    "print('Midterm 1 avg:', np.average(mt1), 'std dev:', np.std(mt1))\n",
    "print('Midterm 2 avg:', np.average(mt2), 'std dev:', np.std(mt2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-lec39-3",
   "metadata": {},
   "source": [
    "### Option 1: Scale Up\n",
    "\n",
    "E.g., if John scored 21 out of 40 on midterm 1, assign him a score of $21/40*50 = 26.25$ out of 50 on midterm. Equivalently, assign him a total score of $21/40*90 = 47.25$.\n",
    "   * What is good and what is bad about this approach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assuming John got a 21 our of 40 on the first midterm. \n",
    "#Use that propotion to approximate the score he would have earned on the second midterm. \n",
    "\n",
    "mt1_actual = 21\n",
    "mt2_estimate_1 = mt1_actual / 40 * 50\n",
    "mt2_estimate_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare that value to the average score on midterm 2\n",
    "\n",
    "mt2_estimate_1 - np.average(mt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many standard deviations below the mean is his assigned score?\n",
    "\n",
    "(mt2_estimate_1 - np.average(mt2)) / np.std(mt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine his actual standard deviation for midterm one. \n",
    "\n",
    "(mt1_actual - np.average(mt1)) / np.std(mt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7debe66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is the median value of midterm 2?\n",
    "\n",
    "np.median(mt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-lec39-8",
   "metadata": {},
   "source": [
    "### Option 2: Z-Score\n",
    "E.g., if John scored 1 standard deviation below the mean on midterm 1, assign him a midterm 2 score that is 1 standard deviation below the mean.\n",
    "   * What is good and what is bad about this approach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Again assuming John scored 21 on the first exam. \n",
    "mt1_actual = 21\n",
    "\n",
    "#Standardize his first midterm score and assign a midterm two score based on the z-score.\n",
    "mt1_z = (mt1_actual - np.average(mt1)) / np.std(mt1)\n",
    "mt2_estimate_2 = np.average(mt2) + mt1_z * np.std(mt2)\n",
    "mt2_estimate_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How far from the mean is the new score?\n",
    "\n",
    "mt2_estimate_2 - np.average(mt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many standard deviations is the new score?\n",
    "\n",
    "(mt2_estimate_2 - np.average(mt2)) / np.std(mt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Review the distribution of the midterm one scores. \n",
    "\n",
    "scores.hist('Midterm 1', unit='point')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Review the distribution for the midterm two scores. \n",
    "\n",
    "scores.hist('Midterm 2', unit='point')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc07ed9",
   "metadata": {},
   "source": [
    "What can you conclude about the two exams by comparing the distributions?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-lec39-14",
   "metadata": {},
   "source": [
    "### Option 3: Percentile\n",
    "Since the distributions are so different, a percentile method may be a better approximation of what John would've actually scored. \n",
    "\n",
    "E.g., if John scored in the 30th percentile on the final, assign him a midterm score that is in the 30th percentile.\n",
    "   * What is good and what is bad about this approach?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Under the same assumption that John scored 21 on midterm one. \n",
    "mt1_actual = 21\n",
    "\n",
    "#Find what percentile he was in for midterm one. \n",
    "\n",
    "mt1_percentile = sum(mt1 <= mt1_actual) / len(mt1) * 100\n",
    "mt1_percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify that value will give back John's actual score. \n",
    "\n",
    "percentile(mt1_percentile, mt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What score would that percentile generate for midterm two?\n",
    "\n",
    "percentile(mt1_percentile, mt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find all the people who got 21 on the midterm one and see where they scored for midterm two. \n",
    "\n",
    "scores.where('Midterm 1', 21).hist('Midterm 2', normed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de034a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What was the average for midterm two of those who scored 21 on midterm one.\n",
    "\n",
    "np.average(scores.where('Midterm 1', 21).column('Midterm 2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-lec39-19",
   "metadata": {},
   "source": [
    "### Option 4: Linear Regression\n",
    "\n",
    "E.g., if John scored 1 standard deviation below the mean on the final, and the correlation coefficient r between midterm and final scores was 0.8 for students who took both, then assign him a midterm score that is 0.8 standard deviations below the mean.\n",
    "   * What is good and what is bad about this approach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Familiar functions to find r, the slope, and the intercept for the linear regression line. \n",
    "def standard_units(arr):\n",
    "    \"\"\"Converts an array to standard units \"\"\"\n",
    "    return (arr - np.average(arr))/np.std(arr)\n",
    "\n",
    "def correlation(t, x, y):\n",
    "    \"\"\"Computes correlation: t is a table, and x and y are column names \"\"\"\n",
    "    x_standard = standard_units(t.column(x))\n",
    "    y_standard = standard_units(t.column(y))\n",
    "    return np.average(x_standard * y_standard)\n",
    "\n",
    "def slope(t, x, y):\n",
    "    \"\"\"Computes the slope of the regression line, like correlation above \"\"\"\n",
    "    r = correlation(t, x, y)\n",
    "    y_sd = np.std(t.column(y))\n",
    "    x_sd = np.std(t.column(x))\n",
    "    return r * y_sd / x_sd\n",
    "\n",
    "def intercept(t, x, y):\n",
    "    \"\"\"Computes the intercept of the regression line, like slope above \"\"\"\n",
    "    x_mean = np.mean(t.column(x))\n",
    "    y_mean = np.mean(t.column(y))\n",
    "    return y_mean - slope(t, x, y)*x_mean\n",
    "\n",
    "def fitted_values(t, x, y):\n",
    "    \"\"\"Return an array of the regression estimates (predictions) at all the x values\"\"\"\n",
    "    a = slope(t, x, y)\n",
    "    b = intercept(t, x, y)\n",
    "    return a*t.column(x) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is the correlation between midterm one and midterm two?\n",
    "\n",
    "r = correlation(scores, 'Midterm 1', 'Midterm 2')\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remember, John got 21 on the first midterm. \n",
    "mt1_actual = 21\n",
    "\n",
    "#Using the stardized score of midterm one adjusted by r. \n",
    "#Apply that two midterm two to see what score he would be assigned. \n",
    "\n",
    "mt1_z = (mt1_actual - np.average(mt1)) / np.std(mt1)\n",
    "mt2_estimate_2 = np.average(mt2) + mt1_z * r * np.std(mt2)\n",
    "mt2_estimate_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regression works best when the association is ...\n",
    "#Is this a linear association? Run the scatter plot to see.\n",
    "\n",
    "scores.scatter('Midterm 1', 'Midterm 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the predicted values based on the slope and intercept of the association. \n",
    "#Linear Regression line.\n",
    "#Does it seem to go thru the middle of the cloud.\n",
    "\n",
    "a = slope(scores, 'Midterm 1', 'Midterm 2')\n",
    "b = intercept(scores, 'Midterm 1', 'Midterm 2')\n",
    "scores.drop(2).with_column('Fitted', a * mt1 + b ).scatter('Midterm 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the scatter of the residuals (errors) to see if it truly is linear. \n",
    "#What should they be centered around? \n",
    "#Does it look like the association is linear?\n",
    "\n",
    "scores.with_column('Residual', mt2 - (a * mt1 + b)).scatter('Midterm 1', 'Residual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Review the histogram of the midterm two scores for those who scored 21 on midterm one.\n",
    "\n",
    "scores.where(\"Midterm 1\", mt1_actual).hist('Midterm 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zoom in the histogram to look at people who scored similar to John (not exactly the same).\n",
    "#How did they do on midterm two?\n",
    "\n",
    "scores.where(\"Midterm 1\", are.between_or_equal_to(mt1_actual-2, mt1_actual+2)).hist('Midterm 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to find all the students who got similar midterm one score (within two points).\n",
    "#Then find the average of their midterm two scores. \n",
    "\n",
    "def avg_mt2(mt1):\n",
    "    near = scores.where(\"Midterm 1\", are.between_or_equal_to(mt1-2, mt1+2))\n",
    "    return near.column(\"Midterm 2\").mean()\n",
    "\n",
    "#Run the function for John's actual midterm one score.\n",
    "#What is the average midterm two for those who have similar midterm one scores.\n",
    "\n",
    "avg_mt2(mt1_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an array of the average score for every midterm one score.\n",
    "mt2_avg = scores.apply(avg_mt2, 'Midterm 1')\n",
    "mt2_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the averages on the scatter to see if it's a linear association. \n",
    "\n",
    "scores.drop(2).with_column('Avg', mt2_avg).scatter('Midterm 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178fbd3c",
   "metadata": {},
   "source": [
    "Does this appear to be a linear association? \n",
    "\n",
    "Would the linear regression line approximate well enough?\n",
    "\n",
    "Of all the methods of approximating a missing grade, which do you think is the fairest and most accurate? Why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-lec39-31",
   "metadata": {},
   "source": [
    "## Tutoring\n",
    "\n",
    "The scores we were using were from Berkeley CS61A: Program Structures, shortly after they introduced optional small group tutoring. \n",
    "\n",
    "Fall 2017 small-group mentoring/tutoring \n",
    "* There were 84 mentors available for the 587 students in this course over 140 sections in the mentoring programs. \n",
    "* There were 1000 students who did not sign up for the mentoring.  \n",
    "\n",
    "The question: Does the mentoring actually help student to be better prepared for midterm two?\n",
    "\n",
    "Students were given the option to join the mentoring program after they completed midterm one. </br>\n",
    "Mentoring sessions ran for several weeks between midterm one and midterm two.  </br>\n",
    "Students then took midterm two. </br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show complete table that included the mentoring column. \n",
    "#True means they joined and False means they did not join. \n",
    "\n",
    "scores.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run a scatter grouped by whether they were mentored or not. \n",
    "\n",
    "scores.scatter('Midterm 1', 'Midterm 2', group='Mentored')\n",
    "\n",
    "#What do you notice?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run a histogram grouped by mentoring for midterm one scores.\n",
    "\n",
    "scores.hist('Midterm 1', group='Mentored', bins=np.arange(0, 41, 5), normed=False)\n",
    "\n",
    "#What do you notice?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run a histogram grouped by mentoring for midterm two scores.\n",
    "\n",
    "scores.hist('Midterm 2', group='Mentored', bins=np.arange(0, 51, 5), normed=False)\n",
    "\n",
    "#What do you notice?\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a graph of averages of the midterm two score for those who did NOT sign up for mentoring.\n",
    "no_mentor = scores.where(\"Mentored\", False)\n",
    "\n",
    "def avg_mt2_no_mentor(mt1):\n",
    "    near = no_mentor.where(\"Midterm 1\", are.between_or_equal_to(mt1-2, mt1+2))\n",
    "    return near.column(\"Midterm 2\").mean()\n",
    "\n",
    "predicted_mt2 = scores.apply(avg_mt2_no_mentor, \"Midterm 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the predicted values of the midterm two score for those who were not mentored to the scatter. \n",
    "\n",
    "scores.drop(2).with_column('Predicted Mt2', predicted_mt2).scatter('Midterm 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute all students improvement based on the control group of those who did not go to mentoring. \n",
    "#How much better did they do on midterm two compared to midterm one grouped by mentoring?\n",
    "#Basically, we are looking at the residuals compared to the predicted values.\n",
    "\n",
    "scores = scores.with_column(\"Improvement\", scores.column('Midterm 2') - predicted_mt2)\n",
    "\n",
    "scores.hist(\"Improvement\", bins=np.arange(-30, 31, 5), group=\"Mentored\", unit=\"point\")\n",
    "\n",
    "#What is the shape of the graph from those who did not go to mentoring? Where is it centered?\n",
    "\n",
    "#What can you say about those who did go to mentoring?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db2bcdf",
   "metadata": {},
   "source": [
    "### The Test\n",
    "Create a confidence interval for how much people tended to improve over what was expected on average.\n",
    "\n",
    "The Hypothesis Test: Does that confidence interval contain zero?\n",
    "\n",
    "Null Hypothesis: There is no difference between those who mentored and those who did not. </br>\n",
    "Alternate Hypothesis: There is a difference (or those who mentored scored higher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def of_at_least_5(values):\n",
    "    return sum(values >= 5) / len(values)\n",
    "\n",
    "scores.select('Mentored', 'Improvement').group('Mentored', of_at_least_5).set_format(1, PercentFormatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How much did students improve, on average, based on mentoring group. \n",
    "\n",
    "scores.group(\"Mentored\", np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create 95% confidence intervals for each group. \n",
    "def mean_ci(observations):\n",
    "    means = []\n",
    "    for i in np.arange(2000):\n",
    "        means.append(observations.sample().column(\"Improvement\").mean())\n",
    "    lower, upper = percentile(2.5, means), percentile(97.5, means)\n",
    "    print(\"Mean improvement:\", observations.column(\"Improvement\").mean())\n",
    "    print(\"95% CI of mean improvement:\", lower, \"to\", upper)\n",
    "\n",
    "mentored = scores.where(\"Mentored\", True)\n",
    "mean_ci(mentored)\n",
    "\n",
    "#Would you reject the null? Why or Why not?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What about for students who scored below 20 on midterm one?\n",
    "\n",
    "mean_ci(mentored.where(\"Midterm 1\", are.below(20)))\n",
    "\n",
    "#What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What about for students who scored between 20 and 30 on midterm one?\n",
    "\n",
    "mean_ci(mentored.where(\"Midterm 1\", are.between(20, 30)))\n",
    "\n",
    "#What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec39-44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What about for students who scored above 30 on midterm one?\n",
    "\n",
    "mean_ci(mentored.where(\"Midterm 1\", are.above_or_equal_to(30)))\n",
    "\n",
    "#What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc8b5dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
